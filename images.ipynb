{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "\n",
    "def generate_image(api_key, prompt, model_id=\"stabilityai/stable-diffusion-xl-base-1.0\"):\n",
    "    \"\"\"\n",
    "    Generate an image based on a text prompt using Hugging Face's API.\n",
    "    \n",
    "    Parameters:\n",
    "    - api_key: Your Hugging Face API key\n",
    "    - prompt: Description of the image to generate\n",
    "    - model_id: The Hugging Face model ID to use\n",
    "    \"\"\"\n",
    "    if not api_key.strip():\n",
    "        return None, \"Error: Please enter your Hugging Face API key\"\n",
    "    \n",
    "    if not prompt.strip():\n",
    "        return None, \"Error: Please enter a prompt\"\n",
    "    \n",
    "    try:\n",
    "        # Add retry logic\n",
    "        max_retries = 3\n",
    "        retry_count = 0\n",
    "        \n",
    "        while retry_count < max_retries:\n",
    "            try:\n",
    "                # Set up the API call to Hugging Face\n",
    "                API_URL = f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
    "                headers = {\n",
    "                    \"Authorization\": f\"Bearer {api_key}\",\n",
    "                    \"Content-Type\": \"application/json\"\n",
    "                }\n",
    "                \n",
    "                # Prepare the payload based on the model type\n",
    "                if \"controlnet\" in model_id.lower():\n",
    "                    payload = {\n",
    "                        \"inputs\": {\n",
    "                            \"prompt\": prompt,\n",
    "                            \"image\": None  # You would need to add image handling for ControlNet\n",
    "                        }\n",
    "                    }\n",
    "                elif \"instruct-pix2pix\" in model_id.lower():\n",
    "                    payload = {\n",
    "                        \"inputs\": {\n",
    "                            \"prompt\": prompt,\n",
    "                            \"image\": None  # You would need to add image handling for Pix2Pix\n",
    "                        }\n",
    "                    }\n",
    "                else:\n",
    "                    # Standard text-to-image model\n",
    "                    payload = {\n",
    "                        \"inputs\": prompt,\n",
    "                        \"parameters\": {\n",
    "                            \"num_inference_steps\": 30,\n",
    "                            \"guidance_scale\": 7.5,\n",
    "                            \"width\": 768,\n",
    "                            \"height\": 768\n",
    "                        }\n",
    "                    }\n",
    "                \n",
    "                # Make the API request\n",
    "                response = requests.post(API_URL, headers=headers, json=payload, timeout=90)\n",
    "                \n",
    "                # Handle different response types\n",
    "                if response.status_code == 200:\n",
    "                    # Success\n",
    "                    if response.headers.get(\"content-type\") == \"application/json\":\n",
    "                        # Some models return JSON with image data\n",
    "                        data = response.json()\n",
    "                        if isinstance(data, list) and len(data) > 0 and \"image\" in data[0]:\n",
    "                            img_data = base64.b64decode(data[0][\"image\"])\n",
    "                        else:\n",
    "                            return None, f\"Error: Unexpected JSON response format from {model_id}\"\n",
    "                    else:\n",
    "                        # Most models return the image directly\n",
    "                        img_data = response.content\n",
    "                    \n",
    "                    # Create PIL image from the data\n",
    "                    img = Image.open(io.BytesIO(img_data))\n",
    "                    return img, f\"Success! Image generated using {model_id}.\"\n",
    "                    \n",
    "                elif response.status_code == 503:\n",
    "                    # Model is loading\n",
    "                    retry_count += 1\n",
    "                    wait_time = 2 ** retry_count\n",
    "                    try:\n",
    "                        data = response.json()\n",
    "                        if \"estimated_time\" in data:\n",
    "                            wait_time = max(wait_time, data[\"estimated_time\"])\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    time.sleep(wait_time)\n",
    "                    continue\n",
    "                    \n",
    "                elif response.status_code == 429:\n",
    "                    # Rate limit\n",
    "                    retry_count += 1\n",
    "                    time.sleep(2 ** retry_count)\n",
    "                    continue\n",
    "                    \n",
    "                else:\n",
    "                    return None, f\"Error {response.status_code}: {response.text}\"\n",
    "            \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                retry_count += 1\n",
    "                if retry_count >= max_retries:\n",
    "                    return None, f\"Error: Connection failed after multiple attempts: {str(e)}\"\n",
    "                time.sleep(2 ** retry_count)\n",
    "        \n",
    "        # If we've reached here, we've exhausted our retries\n",
    "        return None, \"Error: Failed to generate image after multiple attempts\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return None, f\"Error: {str(e)}\"\n",
    "\n",
    "def generate_prompt_from_image(api_key, input_image):\n",
    "    \"\"\"\n",
    "    Generate a detailed prompt from an uploaded image using Hugging Face's image-to-text models.\n",
    "    \n",
    "    Parameters:\n",
    "    - api_key: Hugging Face API key\n",
    "    - input_image: The source image to analyze\n",
    "    \"\"\"\n",
    "    if not api_key.strip():\n",
    "        return \"Error: Please enter your Hugging Face API key\"\n",
    "    \n",
    "    if input_image is None:\n",
    "        return \"Error: Please upload an image\"\n",
    "    \n",
    "    # Try with Hugging Face API\n",
    "    try:\n",
    "        # Convert to RGB if needed and resize if too large\n",
    "        input_image = input_image.convert(\"RGB\")\n",
    "        max_size = 1024\n",
    "        if input_image.width > max_size or input_image.height > max_size:\n",
    "            input_image.thumbnail((max_size, max_size), Image.LANCZOS)\n",
    "        \n",
    "        # Convert image to bytes\n",
    "        buffered = io.BytesIO()\n",
    "        input_image.save(buffered, format=\"JPEG\")\n",
    "        image_bytes = buffered.getvalue()\n",
    "        \n",
    "        # Try different image captioning models\n",
    "        models = [\n",
    "            \"Salesforce/blip-image-captioning-large\",\n",
    "            \"nlpconnect/vit-gpt2-image-captioning\",\n",
    "            \"microsoft/git-large-coco\"\n",
    "        ]\n",
    "        \n",
    "        for model_id in models:\n",
    "            try:\n",
    "                API_URL = f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
    "                headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "                \n",
    "                response = requests.post(\n",
    "                    API_URL,\n",
    "                    headers=headers,\n",
    "                    data=image_bytes,\n",
    "                    timeout=30\n",
    "                )\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    data = response.json()\n",
    "                    \n",
    "                    # Handle different response formats\n",
    "                    if isinstance(data, list):\n",
    "                        if len(data) > 0 and isinstance(data[0], dict) and \"generated_text\" in data[0]:\n",
    "                            caption = data[0][\"generated_text\"]\n",
    "                        elif len(data) > 0 and isinstance(data[0], str):\n",
    "                            caption = data[0]\n",
    "                        else:\n",
    "                            continue\n",
    "                    elif isinstance(data, dict) and \"generated_text\" in data:\n",
    "                        caption = data[\"generated_text\"]\n",
    "                    else:\n",
    "                        continue\n",
    "                    \n",
    "                    # Enhance the caption\n",
    "                    return f\"{caption}, highly detailed, professional, sharp focus, high resolution\"\n",
    "                \n",
    "                elif response.status_code == 503:\n",
    "                    # Model is loading, try the next one\n",
    "                    continue\n",
    "            except:\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # If all API attempts fail, use fallback method\n",
    "    return generate_fallback_prompt(input_image)\n",
    "\n",
    "def generate_fallback_prompt(image):\n",
    "    \"\"\"\n",
    "    Generate a basic prompt from an image when API fails.\n",
    "    Uses simple image analysis to create a description.\n",
    "    \"\"\"\n",
    "    # Convert to small size for analysis\n",
    "    img = image.copy()\n",
    "    img.thumbnail((100, 100))\n",
    "    \n",
    "    # Simple color analysis\n",
    "    colors = img.getcolors(10000)\n",
    "    if colors:\n",
    "        colors.sort(reverse=True, key=lambda x: x[0])\n",
    "        dominant_colors = colors[:3]\n",
    "        \n",
    "        # Map RGB to basic color names\n",
    "        color_names = []\n",
    "        for count, (r, g, b) in dominant_colors:\n",
    "            if r > 200 and g > 200 and b > 200:\n",
    "                color_names.append(\"white\")\n",
    "            elif r < 60 and g < 60 and b < 60:\n",
    "                color_names.append(\"black\")\n",
    "            elif r > 200 and g < 100 and b < 100:\n",
    "                color_names.append(\"red\")\n",
    "            elif r < 100 and g > 200 and b < 100:\n",
    "                color_names.append(\"green\")\n",
    "            elif r < 100 and g < 100 and b > 200:\n",
    "                color_names.append(\"blue\")\n",
    "            elif r > 200 and g > 200 and b < 100:\n",
    "                color_names.append(\"yellow\")\n",
    "            else:\n",
    "                color_names.append(\"colorful\")\n",
    "        \n",
    "        color_desc = \" and \".join(list(set(color_names))[:2])\n",
    "    else:\n",
    "        color_desc = \"colorful\"\n",
    "    \n",
    "    # Brightness analysis\n",
    "    brightness = sum(img.convert(\"L\").getdata()) / (img.width * img.height)\n",
    "    if brightness > 200:\n",
    "        light_desc = \"bright\"\n",
    "    elif brightness < 50:\n",
    "        light_desc = \"dark\"\n",
    "    else:\n",
    "        light_desc = \"balanced\"\n",
    "    \n",
    "    # Aspect ratio for scene type guessing\n",
    "    aspect = img.width / img.height\n",
    "    if aspect > 1.2:\n",
    "        scene_type = \"landscape\"\n",
    "    elif aspect < 0.8:\n",
    "        scene_type = \"portrait\"\n",
    "    else:\n",
    "        scene_type = \"scene\"\n",
    "    \n",
    "    # Random adjectives to enrich description\n",
    "    adjectives = [\"detailed\", \"beautiful\", \"stunning\", \"professional\", \"high-quality\", \n",
    "                  \"artistic\", \"creative\", \"impressive\", \"elegant\", \"dynamic\"]\n",
    "    \n",
    "    # Generate prompt\n",
    "    prompt = f\"A {random.choice(adjectives)} {light_desc} {scene_type} with {color_desc} elements, highly detailed, professional photography, sharp focus, high resolution\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "# Create Gradio interface\n",
    "with gr.Blocks(title=\"Hugging Face Image Generator\") as app:\n",
    "    gr.Markdown(\"# Hugging Face Image Generator\")\n",
    "    \n",
    "    with gr.Tabs():\n",
    "        with gr.TabItem(\"Text to Image\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    api_key_txt = gr.Textbox(\n",
    "                        label=\"API Key\", \n",
    "                        placeholder=\"Enter your Hugging Face API key\",\n",
    "                        type=\"password\"\n",
    "                    )\n",
    "                    prompt_txt = gr.Textbox(\n",
    "                        label=\"Prompt\", \n",
    "                        placeholder=\"Describe the image you want to generate\",\n",
    "                        lines=3\n",
    "                    )\n",
    "                    # Add model selection dropdown with popular Hugging Face models\n",
    "                    model_txt = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "                            \"runwayml/stable-diffusion-v1-5\",\n",
    "                            \"CompVis/stable-diffusion-v1-4\",\n",
    "                            \"stabilityai/stable-diffusion-2-1\",\n",
    "                            \"dreamlike-art/dreamlike-diffusion-1.0\",\n",
    "                            \"prompthero/openjourney\",\n",
    "                            \"andite/anything-v4.0\",\n",
    "                            \"hakurei/waifu-diffusion\",\n",
    "                            \"dalle-mini/dalle-mini\",\n",
    "                            \"sd-dreambooth-library/herge-style\",\n",
    "                            \"nitrosocke/Ghibli-Diffusion\",\n",
    "                            \"eimiss/EimisAnimeDiffusion_1.0v\",\n",
    "                            \"sd-dreambooth-library/van-gogh-diffusion\",\n",
    "                            \"facebook/bart-large-cnn\",\n",
    "                            \"cjwbw/stable-diffusion-v1-5-lightning\",\n",
    "                            \"stabilityai/sdxl-turbo\",\n",
    "                            \"runwayml/stable-diffusion-inpainting\",\n",
    "                            \"timbrooks/instruct-pix2pix\"\n",
    "                        ],\n",
    "                        value=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "                        label=\"Select Model\"\n",
    "                    )\n",
    "                    generate_btn = gr.Button(\"Generate Image\", variant=\"primary\")\n",
    "                    \n",
    "                with gr.Column():\n",
    "                    output_image_txt = gr.Image(label=\"Generated Image\")\n",
    "                    output_message_txt = gr.Textbox(label=\"Status\")\n",
    "            \n",
    "            # Add some examples\n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    [\"A peaceful countryside with a small cottage\"],\n",
    "                    [\"A young girl with a cat in a magical forest\"],\n",
    "                    [\"A floating castle in the sky with airships\"],\n",
    "                    [\"A quiet riverside town at sunset\"],\n",
    "                ],\n",
    "                inputs=prompt_txt\n",
    "            )\n",
    "            \n",
    "        with gr.TabItem(\"Prompt Generator\"):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    api_key_prompt = gr.Textbox(\n",
    "                        label=\"API Key\", \n",
    "                        placeholder=\"Enter your Hugging Face API key\",\n",
    "                        type=\"password\"\n",
    "                    )\n",
    "                    input_image_prompt = gr.Image(\n",
    "                        label=\"Upload Image to Generate Prompt\", \n",
    "                        type=\"pil\"\n",
    "                    )\n",
    "                    generate_prompt_btn = gr.Button(\"Generate Detailed Prompt\", variant=\"primary\")\n",
    "                    generated_prompt = gr.Textbox(\n",
    "                        label=\"Generated Prompt\", \n",
    "                        lines=4,\n",
    "                        placeholder=\"Your detailed prompt will appear here...\"\n",
    "                    )\n",
    "                    use_prompt_btn = gr.Button(\"Use this Prompt to Generate Image\")\n",
    "                    # Add model selection dropdown for prompt tab\n",
    "                    model_prompt = gr.Dropdown(\n",
    "                        choices=[\n",
    "                            \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "                            \"runwayml/stable-diffusion-v1-5\",\n",
    "                            \"CompVis/stable-diffusion-v1-4\",\n",
    "                            \"stabilityai/stable-diffusion-2-1\",\n",
    "                            \"dreamlike-art/dreamlike-diffusion-1.0\",\n",
    "                            \"prompthero/openjourney\",\n",
    "                            \"andite/anything-v4.0\",\n",
    "                            \"hakurei/waifu-diffusion\",\n",
    "                            \"dalle-mini/dalle-mini\",\n",
    "                            \"sd-dreambooth-library/herge-style\",\n",
    "                            \"nitrosocke/Ghibli-Diffusion\",\n",
    "                            \"eimiss/EimisAnimeDiffusion_1.0v\",\n",
    "                            \"sd-dreambooth-library/van-gogh-diffusion\",\n",
    "                            \"facebook/bart-large-cnn\",\n",
    "                            \"cjwbw/stable-diffusion-v1-5-lightning\",\n",
    "                            \"stabilityai/sdxl-turbo\",\n",
    "                            \"runwayml/stable-diffusion-inpainting\",\n",
    "                            \"timbrooks/instruct-pix2pix\"\n",
    "                        ],\n",
    "                        value=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "                        label=\"Select Model for New Image\"\n",
    "                    )\n",
    "                \n",
    "                with gr.Column():\n",
    "                    output_image_prompt = gr.Image(label=\"Generated Image\")\n",
    "                    output_message_prompt = gr.Textbox(label=\"Status\")\n",
    "    \n",
    "    # Add information about Hugging Face Models\n",
    "    gr.Markdown(\"\"\"\n",
    "    ## Features:\n",
    "    - **Text to Image**: Create images from your text descriptions using Hugging Face models\n",
    "    - **Prompt Generator**: Upload an image to get a detailed prompt, then use that prompt to generate new images\n",
    "    - **Multiple Models**: Choose from different Hugging Face diffusion models\n",
    "    - The API key is only used to make requests to Hugging Face and is not stored\n",
    "    \n",
    "    ## Popular Models:\n",
    "    - **stabilityai/stable-diffusion-xl-base-1.0**: High-quality SDXL model\n",
    "    - **runwayml/stable-diffusion-v1-5**: Classic Stable Diffusion model\n",
    "    - **nitrosocke/Ghibli-Diffusion**: Generates images in Studio Ghibli style\n",
    "    - **prompthero/openjourney**: Midjourney-inspired style\n",
    "    - **andite/anything-v4.0**: Anime-style generations\n",
    "    - **hakurei/waifu-diffusion**: Anime character generations\n",
    "    - **sd-dreambooth-library/herge-style**: Tintin comic style\n",
    "    - **sd-dreambooth-library/van-gogh-diffusion**: Van Gogh painting style\n",
    "    - **timbrooks/instruct-pix2pix**: Image editing model\n",
    "    \n",
    "    ## Note:\n",
    "    - Some models may take longer to load if they haven't been used recently\n",
    "    - If the Hugging Face server is experiencing issues, the app will use a fallback method to generate prompts\n",
    "    - Different models may have different optimal prompt styles\n",
    "    \"\"\")\n",
    "    \n",
    "    # Connect the button clicks to the functions\n",
    "    generate_btn.click(\n",
    "        fn=generate_image,\n",
    "        inputs=[api_key_txt, prompt_txt, model_txt],\n",
    "        outputs=[output_image_txt, output_message_txt]\n",
    "    )\n",
    "    \n",
    "    generate_prompt_btn.click(\n",
    "        fn=generate_prompt_from_image,\n",
    "        inputs=[api_key_prompt, input_image_prompt],\n",
    "        outputs=generated_prompt\n",
    "    )\n",
    "    \n",
    "    use_prompt_btn.click(\n",
    "        fn=generate_image,\n",
    "        inputs=[api_key_prompt, generated_prompt, model_prompt],\n",
    "        outputs=[output_image_prompt, output_message_prompt]\n",
    "    )\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    app.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
